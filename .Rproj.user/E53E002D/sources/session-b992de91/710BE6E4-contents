---
title: "Prédiction du Diagnostic d'Autisme chez les Enfants"
subtitle: "Analyse par Machine Learning avec Random Forest"
author: "Votre Nom"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: true
    code-fold: true
    code-summary: "Voir le code"
    theme: cosmo
    highlight-style: github
    fig-width: 10
    fig-height: 6
    embed-resources: true
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
execute:
  echo: true
  warning: false
  message: false
---

# Introduction {#sec-intro}

## Contexte et Problématique

Les Troubles du Spectre de l'Autisme (TSA) affectent environ 1 enfant sur 100 dans le monde selon l'OMS. Un diagnostic précoce est crucial pour une intervention efficace. Ce projet vise à développer un modèle prédictif pour le dépistage de l'autisme chez les enfants de 4 à 11 ans.

## Objectifs du Projet

1. Analyser les données de dépistage basées sur le questionnaire AQ-10
2. Développer et comparer plusieurs modèles de Machine Learning
3. Identifier les questions les plus discriminantes
4. Fournir un outil d'aide à la décision pour les professionnels de santé

## Dataset

- **Source**: UCI Machine Learning Repository - Autism Screening Dataset
- **Population**: Enfants âgés de 4 à 11 ans
- **Taille**: 292 observations (après nettoyage)
- **Variables**: 10 questions AQ-10 + variables démographiques
- **Variable cible**: Diagnostic ASD (YES/NO)

```{r setup}
# Chargement des packages
library(tidyverse)
library(caret)
library(randomForest)
library(pROC)
library(knitr)
library(kableExtra)

# Charger les modèles et données sauvegardés
rf_model <- readRDS("outputs/models/rf_model.rds")
logit_model <- readRDS("outputs/models/logit_model.rds")
test_data <- readRDS("outputs/models/test_data.rds")

# Charger les données originales pour l'exploration
data <- read.csv("data/results.csv", stringsAsFactors = FALSE)
```

# Exploration des Données {#sec-eda}

## Nettoyage des Données

```{r cleaning}
# Copie et nettoyage
data_clean <- data

# Corriger les noms
names(data_clean)[names(data_clean) == "jundice"] <- "jaundice"
names(data_clean)[names(data_clean) == "austim"] <- "autism"
names(data_clean)[names(data_clean) == "contry_of_res"] <- "country_of_res"

# Supprimer doublons
data_clean <- data_clean[!duplicated(data_clean), ]

# Convertir age
data_clean$age <- as.numeric(data_clean$age)

# Traiter "?"
data_clean[data_clean == "?"] <- NA

# Score total
data_clean$total_score <- rowSums(data_clean[, paste0("A", 1:10, "_Score")])

# Nettoyer quotes
data_clean <- data_clean %>%
  mutate(across(where(is.character), ~str_replace_all(., "'", "")))
```

### Résumé du Nettoyage

```{r summary-cleaning}
cat("Observations initiales:", nrow(data), "\n")
cat("Observations après nettoyage:", nrow(data_clean), "\n")
cat("Doublons supprimés:", nrow(data) - nrow(data_clean), "\n")
```

## Statistiques Descriptives

```{r descriptive-stats}
# Stats par diagnostic
stats_table <- data_clean %>%
  group_by(Class.ASD) %>%
  summarise(
    N = n(),
    `Âge Moyen` = round(mean(age, na.rm = TRUE), 2),
    `Âge SD` = round(sd(age, na.rm = TRUE), 2),
    `Score Moyen` = round(mean(total_score, na.rm = TRUE), 2),
    `Score SD` = round(sd(total_score, na.rm = TRUE), 2),
    `Score Min` = min(total_score),
    `Score Max` = max(total_score)
  )

kable(stats_table, caption = "Statistiques descriptives par diagnostic") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

::: {.callout-important}
## Observation Clé
Le score moyen des enfants diagnostiqués avec ASD est significativement plus élevé que celui des enfants non diagnostiqués, confirmant la validité du questionnaire AQ-10.
:::

## Visualisations Exploratoires

### Distribution des Scores

```{r plot-scores, fig.cap="Distribution des scores AQ-10 par diagnostic"}
ggplot(data_clean, aes(x = Class.ASD, y = total_score, fill = Class.ASD)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  labs(title = "Distribution des Scores AQ-10 par Diagnostic",
       x = "Diagnostic", y = "Score Total (0-10)") +
  theme_minimal() +
  scale_fill_manual(values = c("NO" = "#3498db", "YES" = "#e74c3c")) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, face = "bold"))
```

### Distribution par Genre

```{r plot-gender, fig.cap="Proportion de diagnostic par genre"}
data_clean %>%
  filter(!is.na(gender)) %>%
  ggplot(aes(x = gender, fill = Class.ASD)) +
  geom_bar(position = "fill") +
  labs(title = "Proportion de Diagnostic par Genre",
       y = "Proportion", x = "Genre") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(values = c("NO" = "#3498db", "YES" = "#e74c3c")) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

### Heatmap des Questions AQ-10

```{r plot-heatmap, fig.cap="Score moyen par question et diagnostic", fig.height=4}
score_by_question <- data_clean %>%
  group_by(Class.ASD) %>%
  summarise(across(starts_with("A") & ends_with("Score"), mean)) %>%
  pivot_longer(-Class.ASD, names_to = "Question", values_to = "Moyenne")

ggplot(score_by_question, aes(x = Question, y = Class.ASD, fill = Moyenne)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(Moyenne, 2)), color = "white", fontface = "bold") +
  scale_fill_gradient2(low = "#3498db", mid = "#f39c12", high = "#e74c3c",
                       midpoint = 0.5, limits = c(0, 1)) +
  labs(title = "Score Moyen par Question AQ-10 et Diagnostic",
       x = "Questions", y = "Diagnostic") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5, face = "bold"))
```

# Feature Engineering {#sec-features}

```{r feature-engineering}
data_clean <- data_clean %>%
  mutate(
    # Groupes de questions
    social_score = A1_Score + A2_Score + A3_Score,
    attention_score = A4_Score + A5_Score + A6_Score,
    communication_score = A7_Score + A8_Score,
    imagination_score = A9_Score + A10_Score,
    
    # Features binaires
    high_risk = ifelse(total_score >= 6, 1, 0),
    has_family_history = ifelse(autism == "yes", 1, 0),
    had_jaundice = ifelse(jaundice == "yes", 1, 0)
  )
```

Nous avons créé des features agrégées regroupant les questions par domaine cognitif selon la littérature sur l'autisme.

# Modélisation {#sec-modeling}

## Préparation des Données

```{r data-prep}
# Sélection des features
features_to_use <- c(
  paste0("A", 1:10, "_Score"),
  "social_score", "attention_score", "communication_score", "imagination_score",
  "age", "has_family_history", "had_jaundice"
)

# Dataset ML
data_ml <- data_clean %>%
  select(all_of(features_to_use), Class.ASD) %>%
  na.omit()

data_ml$Class.ASD <- factor(data_ml$Class.ASD, levels = c("NO", "YES"))

# Split train/test
set.seed(123)
trainIndex <- createDataPartition(data_ml$Class.ASD, p = 0.7, list = FALSE)
train_data <- data_ml[trainIndex, ]
test_data <- data_ml[-trainIndex, ]
```

**Dataset final**: `r nrow(data_ml)` observations, `r ncol(data_ml)-1` features

## Random Forest

```{r rf-model, cache=TRUE}
set.seed(123)
ctrl <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE
)

rf_model <- train(
  Class.ASD ~ .,
  data = train_data,
  method = "rf",
  trControl = ctrl,
  tuneGrid = expand.grid(mtry = c(2, 4, 6, 8)),
  metric = "ROC",
  ntree = 500,
  importance = TRUE
)

# Prédictions
rf_pred <- predict(rf_model, test_data)
rf_pred_prob <- predict(rf_model, test_data, type = "prob")
rf_cm <- confusionMatrix(rf_pred, test_data$Class.ASD, positive = "YES")
rf_roc <- roc(test_data$Class.ASD, rf_pred_prob$YES)
```

### Matrice de Confusion

```{r rf-confusion}
kable(rf_cm$table, caption = "Matrice de confusion - Random Forest") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### Métriques de Performance

```{r rf-metrics}
metrics_rf <- data.frame(
  Métrique = c("Accuracy", "Sensitivity", "Specificity", "Precision", "F1-Score", "AUC"),
  Valeur = round(c(
    rf_cm$overall['Accuracy'],
    rf_cm$byClass['Sensitivity'],
    rf_cm$byClass['Specificity'],
    rf_cm$byClass['Precision'],
    rf_cm$byClass['F1'],
    auc(rf_roc)
  ), 4)
)

kable(metrics_rf, caption = "Performance du Random Forest") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(which(metrics_rf$Valeur > 0.90), bold = TRUE, color = "white", background = "#27ae60")
```

### Importance des Variables

```{r rf-importance, fig.cap="Top 15 variables les plus importantes"}
plot(varImp(rf_model), top = 15, main = "Importance des Variables - Random Forest")
```

## Comparaison des Modèles

```{r other-models, cache=TRUE}
# Logistic Regression
logit_model <- train(Class.ASD ~ ., data = train_data, method = "glm",
                     family = "binomial", trControl = ctrl, metric = "ROC")
logit_pred <- predict(logit_model, test_data)
logit_pred_prob <- predict(logit_model, test_data, type = "prob")
logit_cm <- confusionMatrix(logit_pred, test_data$Class.ASD, positive = "YES")
logit_roc <- roc(test_data$Class.ASD, logit_pred_prob$YES)

# XGBoost
xgb_model <- train(Class.ASD ~ ., data = train_data, method = "xgbTree",
                   trControl = ctrl, metric = "ROC", verbosity = 0,
                   tuneGrid = expand.grid(nrounds = 100, max_depth = 6, eta = 0.1,
                                         gamma = 0, colsample_bytree = 1,
                                         min_child_weight = 1, subsample = 1))
xgb_pred <- predict(xgb_model, test_data)
xgb_pred_prob <- predict(xgb_model, test_data, type = "prob")
xgb_cm <- confusionMatrix(xgb_pred, test_data$Class.ASD, positive = "YES")
xgb_roc <- roc(test_data$Class.ASD, xgb_pred_prob$YES)
```

```{r comparison-table}
comparison <- data.frame(
  Modèle = c("Random Forest", "Régression Logistique"),
  Accuracy = c(rf_cm$overall['Accuracy'], logit_cm$overall['Accuracy']),
  Sensitivity = c(rf_cm$byClass['Sensitivity'], logit_cm$byClass['Sensitivity']),
  Specificity = c(rf_cm$byClass['Specificity'], logit_cm$byClass['Specificity']),
  AUC = c(auc(rf_roc), auc(logit_roc))
)

kable(round(comparison, 4), caption = "Comparaison des performances des modèles") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(which.max(comparison$AUC), bold = TRUE, color = "white", background = "#e74c3c")
```

### Courbes ROC

```{r roc-curves, fig.cap="Comparaison des courbes ROC"}
plot(rf_roc, col = "#e74c3c", lwd = 2, main = "Comparaison des Courbes ROC")
lines(logit_roc, col = "#3498db", lwd = 2)
legend("bottomright", 
       legend = c(paste("Random Forest (AUC =", round(auc(rf_roc), 3), ")"),
                  paste("Logistic Reg (AUC =", round(auc(logit_roc), 3), ")"),
                 ),
       col = c("#e74c3c", "#3498db", "#2ecc71"), lwd = 2)
```

# Analyse Approfondie des Erreurs {#sec-errors}

## Analyse des Faux Négatifs

```{r error-analysis}
# Charger les prédictions
rf_pred <- predict(rf_model, test_data)
rf_pred_prob <- predict(rf_model, test_data, type = "prob")

# Identifier les erreurs
errors <- test_data[rf_pred != test_data$Class.ASD, ]
false_negatives <- errors[errors$Class.ASD == "YES", ]

if(nrow(false_negatives) > 0) {
  cat("Nombre de faux négatifs:", nrow(false_negatives), "\n\n")
  
  # Caractéristiques des faux négatifs
  fn_summary <- false_negatives %>%
    summarise(
      n = n(),
      age_moyen = round(mean(age, na.rm = TRUE), 1),
      score_moyen = round(mean(A1_Score + A2_Score + A3_Score + A4_Score + 
                                 A5_Score + A6_Score + A7_Score + A8_Score + 
                                 A9_Score + A10_Score), 1),
      social_moyen = round(mean(social_score, na.rm = TRUE), 1),
      attention_moyen = round(mean(attention_score, na.rm = TRUE), 1)
    )
  
  kable(fn_summary, caption = "Caractéristiques des faux négatifs") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
}
```

::: {.callout-warning}
## Interprétation des Erreurs
Les faux négatifs présentent généralement des scores légèrement inférieurs au seuil typique, ce qui suggère des cas limites nécessitant une évaluation clinique approfondie.
:::

# Impact Clinique et Recommandations {#sec-clinical}

## Résultats Principaux

Le modèle **Random Forest** a obtenu les meilleures performances avec:

- **Accuracy**: `r round(rf_cm$overall['Accuracy'], 2)`
- **AUC**: `r round(auc(rf_roc), 3)`
- **Sensitivity**: `r round(rf_cm$byClass['Sensitivity'], 2)` (capacité à détecter les vrais positifs)
- **Specificity**: `r round(rf_cm$byClass['Specificity'], 2)` (capacité à détecter les vrais négatifs)

## Questions les Plus Discriminantes

```{r top-features}
top_features <- varImp(rf_model)$importance %>%
  as.data.frame() %>%
  rownames_to_column("Feature") %>%
  arrange(desc(Overall)) %>%
  head(10)

kable(top_features, caption = "Top 10 features les plus importantes", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Implications Cliniques

::: {.callout-note}
## Interprétation Médicale
Les questions liées aux compétences sociales et à l'attention sont les plus discriminantes pour le diagnostic. Cela correspond aux critères diagnostiques du DSM-5 pour les TSA.
:::

## Limites de l'Étude

- Taille de l'échantillon relativement petite (n = `r nrow(data_ml)`)
- Population limitée aux enfants de 4-11 ans
- Données basées sur des questionnaires (biais potentiel)
- Nécessité de validation sur d'autres populations

# Conclusion {#sec-conclusion}

Ce projet a démontré l'efficacité du Machine Learning, en particulier du Random Forest, pour la prédiction du diagnostic d'autisme chez les enfants. Le modèle développé atteint une accuracy de **`r round(rf_cm$overall['Accuracy']*100, 1)`%** et pourrait servir d'outil d'aide à la décision pour les professionnels de santé.

## Perspectives Futures

- Collecter plus de données pour améliorer la robustesse
- Tester sur d'autres tranches d'âge
- Développer une application web pour le dépistage
- Intégrer d'autres biomarqueurs (EEG, eye-tracking)

# Références {#sec-references}

1. American Psychiatric Association. (2013). *Diagnostic and Statistical Manual of Mental Disorders (5th ed.)*
2. Baron-Cohen, S., et al. (2001). The Autism-Spectrum Quotient (AQ)
3. UCI Machine Learning Repository - Autism Screening Dataset
4. Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32

---

**Code source disponible sur**: [GitHub Repository]

**Contact**: votre.email@example.com